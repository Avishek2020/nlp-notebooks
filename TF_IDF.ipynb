{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF-IDF.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNZTql4wY2qNuTSi+lT8GPz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Avishek2020/nlp-notebooks/blob/master/TF_IDF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95EQNG-q72Dq",
        "colab_type": "text"
      },
      "source": [
        "##Introduction: TF-IDF\n",
        "\n",
        "Reference :- https://towardsdatascience.com/natural-language-processing-feature-engineering-using-tf-idf-e8b9d00e7e76\n",
        "\n",
        "TF-IDF stands for “Term Frequency — Inverse Document Frequency”.\n",
        "\n",
        "TF refer as Term Frequency and is calculated as\n",
        "\n",
        "`TF = (Frequency of the word in the sentence) / (Total number of words in the sentence)`\n",
        "\n",
        "IDF refers to inverse document frequency and is calculated as \n",
        "\n",
        "`IDF: (Total number of sentences (documents))/(Number of sentences (documents) containing the word)`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AGGR1HZ75SI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eURSJHq3o4XT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class tfidf:\n",
        "    def __init__(self,worddict,bagOfWords, documents):\n",
        "        self.worddict   = worddict\n",
        "        self.bagOfWords = bagOfWords\n",
        "        self.documents  = documents\n",
        "    \n",
        "    def tf(self):\n",
        "        tfDict ={}\n",
        "        totalWordsCount = len(self.bagOfWords)\n",
        "        for word, count in self.worddict.items():\n",
        "            tfDict[word] = count/ float(totalWordsCount)\n",
        "        return tfDict\n",
        "\n",
        "    def idf(self):\n",
        "        import math\n",
        "        N =  len(self.documents)          \n",
        "        print(N)\n",
        "        idfDict = dict.fromkeys(self.documents[0].keys(), 0)\n",
        "        for document in self.documents:\n",
        "            for word, val in document.items():\n",
        "                if val > 0:\n",
        "                    idfDict[word] += 1\n",
        "        \n",
        "        for word, val in idfDict.items():\n",
        "            idfDict[word] = math.log(N / float(val))\n",
        "        return idfDict\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MlINX--9E7W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " Stanza1 = \"Two roads diverged in a yellow wood,\"\\\n",
        "           \"And sorry I could not travel both \"\\\n",
        "           \"And be one traveler, long I stood \"\\\n",
        "           \"And looked down one as far as I could \"\\\n",
        "           \"To where it bent in the undergrowth \"\n",
        "Stanza2 =   \"Then took the other, as just as fair ,\"\\\n",
        "            \"And having perhaps the better claim ,\"\\\n",
        "            \"Because it was grassy and wanted wear ;\"\\\n",
        "            \"Though as for that the passing there \"\\\n",
        "            \"Had worn them really about the same \""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lu1eBq17-N2h",
        "colab_type": "code",
        "outputId": "fd07bc3f-c168-47b1-c392-1611394b143d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        }
      },
      "source": [
        "bagOfWordsStanza1 = Stanza1.split(' ')\n",
        "bagOfWordsStanza1 , len(bagOfWordsStanza1)"
      ],
      "execution_count": 503,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['Two',\n",
              "  'roads',\n",
              "  'diverged',\n",
              "  'in',\n",
              "  'a',\n",
              "  'yellow',\n",
              "  'wood,And',\n",
              "  'sorry',\n",
              "  'I',\n",
              "  'could',\n",
              "  'not',\n",
              "  'travel',\n",
              "  'both',\n",
              "  'And',\n",
              "  'be',\n",
              "  'one',\n",
              "  'traveler,',\n",
              "  'long',\n",
              "  'I',\n",
              "  'stood',\n",
              "  'And',\n",
              "  'looked',\n",
              "  'down',\n",
              "  'one',\n",
              "  'as',\n",
              "  'far',\n",
              "  'as',\n",
              "  'I',\n",
              "  'could',\n",
              "  'To',\n",
              "  'where',\n",
              "  'it',\n",
              "  'bent',\n",
              "  'in',\n",
              "  'the',\n",
              "  'undergrowth',\n",
              "  ''],\n",
              " 37)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 503
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-2HVvFJ_LPe",
        "colab_type": "code",
        "outputId": "82b3ac82-75bf-4dd9-9329-dd9743e7e0a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      },
      "source": [
        "bagOfWordsStanza2 = Stanza2.split(' ')\n",
        "bagOfWordsStanza2 ,len(bagOfWordsStanza2)"
      ],
      "execution_count": 504,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['Then',\n",
              "  'took',\n",
              "  'the',\n",
              "  'other,',\n",
              "  'as',\n",
              "  'just',\n",
              "  'as',\n",
              "  'fair',\n",
              "  ',And',\n",
              "  'having',\n",
              "  'perhaps',\n",
              "  'the',\n",
              "  'better',\n",
              "  'claim',\n",
              "  ',Because',\n",
              "  'it',\n",
              "  'was',\n",
              "  'grassy',\n",
              "  'and',\n",
              "  'wanted',\n",
              "  'wear',\n",
              "  ';Though',\n",
              "  'as',\n",
              "  'for',\n",
              "  'that',\n",
              "  'the',\n",
              "  'passing',\n",
              "  'there',\n",
              "  'Had',\n",
              "  'worn',\n",
              "  'them',\n",
              "  'really',\n",
              "  'about',\n",
              "  'the',\n",
              "  'same',\n",
              "  ''],\n",
              " 36)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 504
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qiWL077_pSg",
        "colab_type": "code",
        "outputId": "6ee6ec8b-90ea-46e8-8585-487e05cdb266",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "uniqueWords = set(bagOfWordsStanza1).union(set(bagOfWordsStanza2))\n",
        "uniqueWords , len(uniqueWords)"
      ],
      "execution_count": 505,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'',\n",
              "  ',And',\n",
              "  ',Because',\n",
              "  ';Though',\n",
              "  'And',\n",
              "  'Had',\n",
              "  'I',\n",
              "  'Then',\n",
              "  'To',\n",
              "  'Two',\n",
              "  'a',\n",
              "  'about',\n",
              "  'and',\n",
              "  'as',\n",
              "  'be',\n",
              "  'bent',\n",
              "  'better',\n",
              "  'both',\n",
              "  'claim',\n",
              "  'could',\n",
              "  'diverged',\n",
              "  'down',\n",
              "  'fair',\n",
              "  'far',\n",
              "  'for',\n",
              "  'grassy',\n",
              "  'having',\n",
              "  'in',\n",
              "  'it',\n",
              "  'just',\n",
              "  'long',\n",
              "  'looked',\n",
              "  'not',\n",
              "  'one',\n",
              "  'other,',\n",
              "  'passing',\n",
              "  'perhaps',\n",
              "  'really',\n",
              "  'roads',\n",
              "  'same',\n",
              "  'sorry',\n",
              "  'stood',\n",
              "  'that',\n",
              "  'the',\n",
              "  'them',\n",
              "  'there',\n",
              "  'took',\n",
              "  'travel',\n",
              "  'traveler,',\n",
              "  'undergrowth',\n",
              "  'wanted',\n",
              "  'was',\n",
              "  'wear',\n",
              "  'where',\n",
              "  'wood,And',\n",
              "  'worn',\n",
              "  'yellow'},\n",
              " 57)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 505
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i095SYHfAby7",
        "colab_type": "text"
      },
      "source": [
        "##### Now we need to create dictionary of words and there occurence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YE3DGATvASGu",
        "colab_type": "code",
        "outputId": "e8537fae-6c8f-40e2-f219-68937e6ef73b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986
        }
      },
      "source": [
        "# dict.fromkeys() creates a new dictionary with keys from seq and values set to value.\n",
        "# seq- list of seq to be used for dictionary \n",
        "# value - is optional\n",
        "dictWordsStanza1 = dict.fromkeys(uniqueWords,0)\n",
        "dictWordsStanza1\n",
        "# occurence of words\n",
        "for word in bagOfWordsStanza1:\n",
        "    dictWordsStanza1[word] += 1\n",
        "dictWordsStanza1"
      ],
      "execution_count": 506,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'': 1,\n",
              " ',And': 0,\n",
              " ',Because': 0,\n",
              " ';Though': 0,\n",
              " 'And': 2,\n",
              " 'Had': 0,\n",
              " 'I': 3,\n",
              " 'Then': 0,\n",
              " 'To': 1,\n",
              " 'Two': 1,\n",
              " 'a': 1,\n",
              " 'about': 0,\n",
              " 'and': 0,\n",
              " 'as': 2,\n",
              " 'be': 1,\n",
              " 'bent': 1,\n",
              " 'better': 0,\n",
              " 'both': 1,\n",
              " 'claim': 0,\n",
              " 'could': 2,\n",
              " 'diverged': 1,\n",
              " 'down': 1,\n",
              " 'fair': 0,\n",
              " 'far': 1,\n",
              " 'for': 0,\n",
              " 'grassy': 0,\n",
              " 'having': 0,\n",
              " 'in': 2,\n",
              " 'it': 1,\n",
              " 'just': 0,\n",
              " 'long': 1,\n",
              " 'looked': 1,\n",
              " 'not': 1,\n",
              " 'one': 2,\n",
              " 'other,': 0,\n",
              " 'passing': 0,\n",
              " 'perhaps': 0,\n",
              " 'really': 0,\n",
              " 'roads': 1,\n",
              " 'same': 0,\n",
              " 'sorry': 1,\n",
              " 'stood': 1,\n",
              " 'that': 0,\n",
              " 'the': 1,\n",
              " 'them': 0,\n",
              " 'there': 0,\n",
              " 'took': 0,\n",
              " 'travel': 1,\n",
              " 'traveler,': 1,\n",
              " 'undergrowth': 1,\n",
              " 'wanted': 0,\n",
              " 'was': 0,\n",
              " 'wear': 0,\n",
              " 'where': 1,\n",
              " 'wood,And': 1,\n",
              " 'worn': 0,\n",
              " 'yellow': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 506
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnCnauA4BqjD",
        "colab_type": "code",
        "outputId": "a7267fc6-42ae-462c-f707-31f3ab8c1bb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986
        }
      },
      "source": [
        "dictWordsStanza2 = dict.fromkeys(uniqueWords,0)\n",
        "dictWordsStanza2\n",
        "for word in bagOfWordsStanza2:\n",
        "    dictWordsStanza2[word] += 1\n",
        "dictWordsStanza2"
      ],
      "execution_count": 507,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'': 1,\n",
              " ',And': 1,\n",
              " ',Because': 1,\n",
              " ';Though': 1,\n",
              " 'And': 0,\n",
              " 'Had': 1,\n",
              " 'I': 0,\n",
              " 'Then': 1,\n",
              " 'To': 0,\n",
              " 'Two': 0,\n",
              " 'a': 0,\n",
              " 'about': 1,\n",
              " 'and': 1,\n",
              " 'as': 3,\n",
              " 'be': 0,\n",
              " 'bent': 0,\n",
              " 'better': 1,\n",
              " 'both': 0,\n",
              " 'claim': 1,\n",
              " 'could': 0,\n",
              " 'diverged': 0,\n",
              " 'down': 0,\n",
              " 'fair': 1,\n",
              " 'far': 0,\n",
              " 'for': 1,\n",
              " 'grassy': 1,\n",
              " 'having': 1,\n",
              " 'in': 0,\n",
              " 'it': 1,\n",
              " 'just': 1,\n",
              " 'long': 0,\n",
              " 'looked': 0,\n",
              " 'not': 0,\n",
              " 'one': 0,\n",
              " 'other,': 1,\n",
              " 'passing': 1,\n",
              " 'perhaps': 1,\n",
              " 'really': 1,\n",
              " 'roads': 0,\n",
              " 'same': 1,\n",
              " 'sorry': 0,\n",
              " 'stood': 0,\n",
              " 'that': 1,\n",
              " 'the': 4,\n",
              " 'them': 1,\n",
              " 'there': 1,\n",
              " 'took': 1,\n",
              " 'travel': 0,\n",
              " 'traveler,': 0,\n",
              " 'undergrowth': 0,\n",
              " 'wanted': 1,\n",
              " 'was': 1,\n",
              " 'wear': 1,\n",
              " 'where': 0,\n",
              " 'wood,And': 0,\n",
              " 'worn': 1,\n",
              " 'yellow': 0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 507
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arrAE8aoD2QH",
        "colab_type": "code",
        "outputId": "7b3f98dc-9fe6-43ca-dcc8-39c6d2707af8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986
        }
      },
      "source": [
        "# To calculate Tf for Stanza 1 &2\n",
        "\n",
        "Obj_Stanza1 = tfidf(dictWordsStanza1,bagOfWordsStanza1, None)\n",
        "tf1 = Obj_Stanza1.tf()\n",
        "Obj_Stanza2 = tfidf(dictWordsStanza2,bagOfWordsStanza2, None)\n",
        "tf2 = Obj_Stanza2.tf()\n",
        "tf2"
      ],
      "execution_count": 508,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'': 0.027777777777777776,\n",
              " ',And': 0.027777777777777776,\n",
              " ',Because': 0.027777777777777776,\n",
              " ';Though': 0.027777777777777776,\n",
              " 'And': 0.0,\n",
              " 'Had': 0.027777777777777776,\n",
              " 'I': 0.0,\n",
              " 'Then': 0.027777777777777776,\n",
              " 'To': 0.0,\n",
              " 'Two': 0.0,\n",
              " 'a': 0.0,\n",
              " 'about': 0.027777777777777776,\n",
              " 'and': 0.027777777777777776,\n",
              " 'as': 0.08333333333333333,\n",
              " 'be': 0.0,\n",
              " 'bent': 0.0,\n",
              " 'better': 0.027777777777777776,\n",
              " 'both': 0.0,\n",
              " 'claim': 0.027777777777777776,\n",
              " 'could': 0.0,\n",
              " 'diverged': 0.0,\n",
              " 'down': 0.0,\n",
              " 'fair': 0.027777777777777776,\n",
              " 'far': 0.0,\n",
              " 'for': 0.027777777777777776,\n",
              " 'grassy': 0.027777777777777776,\n",
              " 'having': 0.027777777777777776,\n",
              " 'in': 0.0,\n",
              " 'it': 0.027777777777777776,\n",
              " 'just': 0.027777777777777776,\n",
              " 'long': 0.0,\n",
              " 'looked': 0.0,\n",
              " 'not': 0.0,\n",
              " 'one': 0.0,\n",
              " 'other,': 0.027777777777777776,\n",
              " 'passing': 0.027777777777777776,\n",
              " 'perhaps': 0.027777777777777776,\n",
              " 'really': 0.027777777777777776,\n",
              " 'roads': 0.0,\n",
              " 'same': 0.027777777777777776,\n",
              " 'sorry': 0.0,\n",
              " 'stood': 0.0,\n",
              " 'that': 0.027777777777777776,\n",
              " 'the': 0.1111111111111111,\n",
              " 'them': 0.027777777777777776,\n",
              " 'there': 0.027777777777777776,\n",
              " 'took': 0.027777777777777776,\n",
              " 'travel': 0.0,\n",
              " 'traveler,': 0.0,\n",
              " 'undergrowth': 0.0,\n",
              " 'wanted': 0.027777777777777776,\n",
              " 'was': 0.027777777777777776,\n",
              " 'wear': 0.027777777777777776,\n",
              " 'where': 0.0,\n",
              " 'wood,And': 0.0,\n",
              " 'worn': 0.027777777777777776,\n",
              " 'yellow': 0.0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 508
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwrsSJ4kEcCD",
        "colab_type": "code",
        "outputId": "c4e2d312-b643-4e3f-e315-b47e749fc4d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# To calculate idf for stanza1 & 2\n",
        "documents = ([dictWordsStanza1,dictWordsStanza2])\n",
        "Obj_Stanza12 = tfidf(dictWordsStanza1,bagOfWordsStanza1, documents)\n",
        "idfs = Obj_Stanza12.idf()\n",
        "idfs"
      ],
      "execution_count": 509,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'': 0.0,\n",
              " ',And': 0.6931471805599453,\n",
              " ',Because': 0.6931471805599453,\n",
              " ';Though': 0.6931471805599453,\n",
              " 'And': 0.6931471805599453,\n",
              " 'Had': 0.6931471805599453,\n",
              " 'I': 0.6931471805599453,\n",
              " 'Then': 0.6931471805599453,\n",
              " 'To': 0.6931471805599453,\n",
              " 'Two': 0.6931471805599453,\n",
              " 'a': 0.6931471805599453,\n",
              " 'about': 0.6931471805599453,\n",
              " 'and': 0.6931471805599453,\n",
              " 'as': 0.0,\n",
              " 'be': 0.6931471805599453,\n",
              " 'bent': 0.6931471805599453,\n",
              " 'better': 0.6931471805599453,\n",
              " 'both': 0.6931471805599453,\n",
              " 'claim': 0.6931471805599453,\n",
              " 'could': 0.6931471805599453,\n",
              " 'diverged': 0.6931471805599453,\n",
              " 'down': 0.6931471805599453,\n",
              " 'fair': 0.6931471805599453,\n",
              " 'far': 0.6931471805599453,\n",
              " 'for': 0.6931471805599453,\n",
              " 'grassy': 0.6931471805599453,\n",
              " 'having': 0.6931471805599453,\n",
              " 'in': 0.6931471805599453,\n",
              " 'it': 0.0,\n",
              " 'just': 0.6931471805599453,\n",
              " 'long': 0.6931471805599453,\n",
              " 'looked': 0.6931471805599453,\n",
              " 'not': 0.6931471805599453,\n",
              " 'one': 0.6931471805599453,\n",
              " 'other,': 0.6931471805599453,\n",
              " 'passing': 0.6931471805599453,\n",
              " 'perhaps': 0.6931471805599453,\n",
              " 'really': 0.6931471805599453,\n",
              " 'roads': 0.6931471805599453,\n",
              " 'same': 0.6931471805599453,\n",
              " 'sorry': 0.6931471805599453,\n",
              " 'stood': 0.6931471805599453,\n",
              " 'that': 0.6931471805599453,\n",
              " 'the': 0.0,\n",
              " 'them': 0.6931471805599453,\n",
              " 'there': 0.6931471805599453,\n",
              " 'took': 0.6931471805599453,\n",
              " 'travel': 0.6931471805599453,\n",
              " 'traveler,': 0.6931471805599453,\n",
              " 'undergrowth': 0.6931471805599453,\n",
              " 'wanted': 0.6931471805599453,\n",
              " 'was': 0.6931471805599453,\n",
              " 'wear': 0.6931471805599453,\n",
              " 'where': 0.6931471805599453,\n",
              " 'wood,And': 0.6931471805599453,\n",
              " 'worn': 0.6931471805599453,\n",
              " 'yellow': 0.6931471805599453}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 509
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOCMsnl9NBuL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now we have TF and IDF, by multiplying both we get TF-IDF\n",
        "\n",
        "def computeTFIDF(tfBagsofWords, idfs):\n",
        "    tfidf = {}\n",
        "    for word, val in tfBagsofWords.items():\n",
        "        tfidf[word] = val * idfs[word]\n",
        "    return tfidf\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bk6lBn7nOAhY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986
        },
        "outputId": "fb5f40cc-3f15-459d-9600-b2c52d173a04"
      },
      "source": [
        "tfidfStanza1 = computeTFIDF(tf1, idfs)\n",
        "tfidfStanza1\n",
        "tfidfStanza2 = computeTFIDF(tf2, idfs)\n",
        "tfidfStanza2"
      ],
      "execution_count": 511,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'': 0.0,\n",
              " ',And': 0.01925408834888737,\n",
              " ',Because': 0.01925408834888737,\n",
              " ';Though': 0.01925408834888737,\n",
              " 'And': 0.0,\n",
              " 'Had': 0.01925408834888737,\n",
              " 'I': 0.0,\n",
              " 'Then': 0.01925408834888737,\n",
              " 'To': 0.0,\n",
              " 'Two': 0.0,\n",
              " 'a': 0.0,\n",
              " 'about': 0.01925408834888737,\n",
              " 'and': 0.01925408834888737,\n",
              " 'as': 0.0,\n",
              " 'be': 0.0,\n",
              " 'bent': 0.0,\n",
              " 'better': 0.01925408834888737,\n",
              " 'both': 0.0,\n",
              " 'claim': 0.01925408834888737,\n",
              " 'could': 0.0,\n",
              " 'diverged': 0.0,\n",
              " 'down': 0.0,\n",
              " 'fair': 0.01925408834888737,\n",
              " 'far': 0.0,\n",
              " 'for': 0.01925408834888737,\n",
              " 'grassy': 0.01925408834888737,\n",
              " 'having': 0.01925408834888737,\n",
              " 'in': 0.0,\n",
              " 'it': 0.0,\n",
              " 'just': 0.01925408834888737,\n",
              " 'long': 0.0,\n",
              " 'looked': 0.0,\n",
              " 'not': 0.0,\n",
              " 'one': 0.0,\n",
              " 'other,': 0.01925408834888737,\n",
              " 'passing': 0.01925408834888737,\n",
              " 'perhaps': 0.01925408834888737,\n",
              " 'really': 0.01925408834888737,\n",
              " 'roads': 0.0,\n",
              " 'same': 0.01925408834888737,\n",
              " 'sorry': 0.0,\n",
              " 'stood': 0.0,\n",
              " 'that': 0.01925408834888737,\n",
              " 'the': 0.0,\n",
              " 'them': 0.01925408834888737,\n",
              " 'there': 0.01925408834888737,\n",
              " 'took': 0.01925408834888737,\n",
              " 'travel': 0.0,\n",
              " 'traveler,': 0.0,\n",
              " 'undergrowth': 0.0,\n",
              " 'wanted': 0.01925408834888737,\n",
              " 'was': 0.01925408834888737,\n",
              " 'wear': 0.01925408834888737,\n",
              " 'where': 0.0,\n",
              " 'wood,And': 0.0,\n",
              " 'worn': 0.01925408834888737,\n",
              " 'yellow': 0.0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 511
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BC8AqfTFOkRH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame([tfidfStanza1,tfidfStanza2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IH14r6DOsj_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "1ab14052-184c-4879-ed8f-b30014fdf4f7"
      },
      "source": [
        "df"
      ],
      "execution_count": 515,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>other,</th>\n",
              "      <th>yellow</th>\n",
              "      <th>worn</th>\n",
              "      <th>Had</th>\n",
              "      <th>stood</th>\n",
              "      <th>both</th>\n",
              "      <th>looked</th>\n",
              "      <th>one</th>\n",
              "      <th>Two</th>\n",
              "      <th>,Because</th>\n",
              "      <th>took</th>\n",
              "      <th>sorry</th>\n",
              "      <th>as</th>\n",
              "      <th>a</th>\n",
              "      <th>down</th>\n",
              "      <th>diverged</th>\n",
              "      <th>passing</th>\n",
              "      <th>perhaps</th>\n",
              "      <th>undergrowth</th>\n",
              "      <th>for</th>\n",
              "      <th>And</th>\n",
              "      <th>travel</th>\n",
              "      <th>claim</th>\n",
              "      <th>I</th>\n",
              "      <th>wanted</th>\n",
              "      <th>bent</th>\n",
              "      <th>was</th>\n",
              "      <th>fair</th>\n",
              "      <th>just</th>\n",
              "      <th>roads</th>\n",
              "      <th>Then</th>\n",
              "      <th>wear</th>\n",
              "      <th>could</th>\n",
              "      <th>wood,And</th>\n",
              "      <th>better</th>\n",
              "      <th>about</th>\n",
              "      <th>be</th>\n",
              "      <th>really</th>\n",
              "      <th>;Though</th>\n",
              "      <th>the</th>\n",
              "      <th>long</th>\n",
              "      <th>traveler,</th>\n",
              "      <th>To</th>\n",
              "      <th>and</th>\n",
              "      <th>them</th>\n",
              "      <th>in</th>\n",
              "      <th>not</th>\n",
              "      <th>grassy</th>\n",
              "      <th>,And</th>\n",
              "      <th>same</th>\n",
              "      <th>that</th>\n",
              "      <th>there</th>\n",
              "      <th>it</th>\n",
              "      <th>far</th>\n",
              "      <th>where</th>\n",
              "      <th>having</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.018734</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.018734</td>\n",
              "      <td>0.018734</td>\n",
              "      <td>0.018734</td>\n",
              "      <td>0.037467</td>\n",
              "      <td>0.018734</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.018734</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018734</td>\n",
              "      <td>0.018734</td>\n",
              "      <td>0.018734</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.018734</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.037467</td>\n",
              "      <td>0.018734</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.056201</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.018734</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.018734</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.037467</td>\n",
              "      <td>0.018734</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.018734</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018734</td>\n",
              "      <td>0.018734</td>\n",
              "      <td>0.018734</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.037467</td>\n",
              "      <td>0.018734</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018734</td>\n",
              "      <td>0.018734</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.019254</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.019254</td>\n",
              "      <td>0.019254</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.019254</td>\n",
              "      <td>0.019254</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.019254</td>\n",
              "      <td>0.019254</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.019254</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.019254</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.019254</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.019254</td>\n",
              "      <td>0.019254</td>\n",
              "      <td>0.019254</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.019254</td>\n",
              "      <td>0.019254</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.019254</td>\n",
              "      <td>0.019254</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.019254</td>\n",
              "      <td>0.019254</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.019254</td>\n",
              "      <td>0.019254</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.019254</td>\n",
              "      <td>0.019254</td>\n",
              "      <td>0.019254</td>\n",
              "      <td>0.019254</td>\n",
              "      <td>0.019254</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.019254</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          other,    yellow      worn  ...   it       far     where    having\n",
              "0  0.0  0.000000  0.018734  0.000000  ...  0.0  0.018734  0.018734  0.000000\n",
              "1  0.0  0.019254  0.000000  0.019254  ...  0.0  0.000000  0.000000  0.019254\n",
              "\n",
              "[2 rows x 57 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 515
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQm6hhrdOtch",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}